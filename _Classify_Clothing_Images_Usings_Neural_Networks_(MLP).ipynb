{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "*Classify Clothing Images Usings Neural Networks (MLP).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aawaskita/BukuPython/blob/master/_Classify_Clothing_Images_Usings_Neural_Networks_(MLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Classifying Images of Clothing\n",
        "\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://cdn-images-1.medium.com/max/1200/1*az55lu4udkgtGdYX5inu2w.jpeg\"\n",
        "         alt=\"Fashion MNIST  Classification Problem\"  width=\"800\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "     <a href=\"https://github.com/\"></a><br/>\n",
        "  </td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "Welcome Back , in this tutorial, we'll build and train a machine learning model ( Unsupervised model) to classify images of clothing.\n",
        "\n",
        "Our goal is to get the general sense of a ML project.\n",
        "\n",
        "Let's Start \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0tMfX2vR0uD"
      },
      "source": [
        "## Install and import Packages\n",
        "\n",
        "For this Colab, we'll need [TensorFlow Datasets](https://www.tensorflow.org/datasets/), an API which  we allow us to download and access the datasets we will work with.\n",
        "\n",
        "We're also using a few helper packages like **Numpy**, **mathplotlib** and **math**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7mUJVqcINSM"
      },
      "source": [
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "\n",
        "# TensorFlow and TensorFlow Datasets\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Another libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import tqdm.auto\n",
        "tqdm.tqdm = tqdm.auto.tqdm\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.enable_eager_execution()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import Our dataset : Fashion MNIST "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "We work in this Colab with the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset.\n",
        "\n",
        "Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:\n",
        "\n",
        "\n",
        "\n",
        "1.   60,000 training examples\n",
        "2.   10,000 testing examples\n",
        "3.   10 classes\n",
        "4.   28×28 grayscale/single channel images\n",
        "  \n",
        "\n",
        " The images show individual articles of clothing at low resolution (28 $\\times$ 28 pixels), as shown below:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/05/04/ImagesSageMaker3.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"400\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "     <a href=\"https://github.com/zalandoresearch/fashion-mnist\"></a><br/>\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "source": [
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Uploading the dataset returns the metadata, as well as a **training dataset** and a **test dataset** : \n",
        "\n",
        "* The model will be training using `train_dataset`.\n",
        "* The model will be testing against `test_dataset`.\n",
        "\n",
        "The images are 28 $\\times$ 28 arrays, with pixel values is in the range `[0, 255]`. The *labels* are an array of integers, in the range `[0, 9]`. \n",
        "Each of these integers correspond to the *class* of clothing represented  by the image : \n",
        "The ten fashion class labels include:\n",
        "\n",
        "1.   T-shirt/top\n",
        "2.   Trouser/pants\n",
        "3.    Pullover shirt\n",
        "4.    Dress\n",
        "5.   Coat\n",
        "6.   Sandal\n",
        "7.   Shirt\n",
        "8.   Sneaker\n",
        "9.   Bag\n",
        "10.  Ankle boot\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://cdn-images-1.medium.com/max/1600/1*-kpgaee9X9Gm-SrQKdk_og.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"410\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "     <a href=\"https://github.com/zalandoresearch/fashion-mnist\"></a><br/>\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. \n",
        "\n",
        "Since **class names** are not included in the dataset, it should be stored here to be used when tracing images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "### Explore our dataset\n",
        "\n",
        "Let's explore the format of the dataset before training the model. \n",
        "\n",
        "The following code shows that there are 60,000 images in the training set, and 10000 images in the test set. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaOTZxFzi48X"
      },
      "source": [
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "The value of each pixel in the image data is an integer in the range `[0,255]`. But for to work properly,we need to be normalize  these values  to the range `[0,1]`. So for that we should create a simple normalization function, and then apply it to each image in the test and train datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAsH3Zm-76pB"
      },
      "source": [
        "def normalize(images, labels):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n",
        "\n",
        "train_dataset =  train_dataset.map(normalize)\n",
        "test_dataset  =  test_dataset.map(normalize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIQbEiJGXM-q"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's plot an image to see what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSzE9l7PjHx0"
      },
      "source": [
        "for image, label in test_dataset.take(1):\n",
        "  break\n",
        "image = image.numpy().reshape((28,28))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "Now we display the first 25 images from the *training set* and the class name below each image. \n",
        "\n",
        "Now, we're ready to build and train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTImqg_CaW1"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "i = 0\n",
        "for (image, label) in test_dataset.take(25):\n",
        "    image = image.numpy().reshape((28,28))\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image, cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[label])\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "As we saw in the previous tutorial, building the machine learning model requires configuring the layers of the model and then compiling it.\n",
        "\n",
        "We will build a 2-layer feedforward neural network with 128 units in the hidden layer. the hidden layer will compute a linear function which is then passed into a ReLU activation function. \n",
        "\n",
        "Finally, we will use a Softmax function on the output from our network, to create 10 outputs (1 output for each target class).\n",
        "\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://harishnarayanan.org/images/writing/artistic-style-transfer/neural-network-1-hidden.svg\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"410\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "     <a href=\"https://github.com/zalandoresearch/fashion-mnist\"></a><br/>\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "Let's setup the layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Setup the layers\n",
        "\n",
        "The core element of a neural network is the *layer*. A layer help us to extracts a representation of the input data. A series of connected layers gives a meaningful representation for the problem to be solved.\n",
        "\n",
        "**Note :** Lots of deep learning consists of connecting simple layers. Most layers, such as `tf.keras.layers.Dense`, contain internal parameters that are learned  during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "Our model has three layers:\n",
        "\n",
        "* **input** `tf.keras.layers.Flatten`  :  This layer will transform the images from a 2d-array of 28 $\\times$ 28 pixels), to a 1d-array (lists) of 784 pixels (28\\*28). This layer has no parameters to learn, as it only reformats the data.\n",
        "\n",
        "* **\"hidden\"** `tf.keras.layers.Dense` : A densely connected layer of 128 neurons. The principe is very simple : Each neuron takes as input the 784 nodes of the previous layer, weighting these inputs according to hidden parameters (**weights** )that will be learned during the training, then sends a unique value to the next layer.\n",
        "\n",
        "* **output** `tf.keras.layers.Dense` : A 10-neuron **softmax** ( [Activation Function](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6) )layer. Each neuron represents a class of clothing. As in the previous layer, each neuron takes input from the 128 nodes in the layer before it, weights thats input according to learned parameters, and outputs a value in the range `[0, 1]`, representing the probability that the image belongs to that class. The sum of all 10 neuron values is 1.\n",
        "\n",
        "\n",
        "### Compile the model\n",
        "\n",
        "Now our model is ready for training but it needs a few more settings. These are added during the compiling step:\n",
        "\n",
        "\n",
        "* *Loss function* :  An algorithm for measuring how far the model's outputs are from the desired output. \n",
        "* *Optimizer* : An algorithm to adjust the internal parameters of the model to minimize  loss.\n",
        "* *Metrics* : Used to monitor the training and testing steps. OUr example example uses *accuracy*, the fraction of correctly classified images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "It’s time to pass our Fashion MNIST data into our neural network and see how it performs!\n",
        "\n",
        "First, we define the iteration behavior for the train dataset:\n",
        "1. Repeat forever by specifying `dataset.repeat()` \n",
        "\n",
        "2. The `dataset.shuffle(60000)` randomizes the order so our model cannot learn anything from the order of the examples.\n",
        "\n",
        "3. And `dataset.batch(32)` tells `model.fit` to use batches of 32 images and labels when updating the model variables.\n",
        "\n",
        "the training step is performed by calling the `model.fit` method : \n",
        "\n",
        "1. `train_dataset`:  used to feed the training data to the model \n",
        "\n",
        "2. The model learns to associate images and labels.\n",
        "\n",
        "3. The `epochs=5` parameter limits training to 5 full iterations of the training dataset ( total of 5 * 60000 = 300000 examples) .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Dp8971McQ1"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvwvpA64CaW_"
      },
      "source": [
        "model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "As the model trains, the loss and accuracy metrics are displayed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Evaluate accuracy\n",
        "\n",
        "Then we will compare the performance of the model on the test dataset. In other words, we will evaluate the accuracy. So, for that, we will use all the examples of the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflXLEeECaXC"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "**Note : ** It turns out that the accuracy of the test dataset is less than that of the training dataset. This is perfectly normal because the model was formed on `train_dataset` : When the model sees images (from `test_dataset`), it has never seen during training . We can expect a decrease in performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## Make predictions and explore\n",
        "\n",
        "Now, We can use  the model trained to make predictions about some images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccoz4conNCpl"
      },
      "source": [
        "for test_images, test_labels in test_dataset.take(1):\n",
        "  test_images = test_images.numpy()\n",
        "  test_labels = test_labels.numpy()\n",
        "  predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "source": [
        "predictions.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "As we are 10 output, the our prediction is an array of 10 numbers. These describe the \"confidence\" of the model that the image corresponds to each of the 10 different clothes. We can see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So the model is most confident that this image is a shirt, or `class_names[6]`. And we can check the test label to see this is correct:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcgZR1TvnjM1"
      },
      "source": [
        "**Thanks for your attention **\n",
        "\n",
        "I wish that you enjoyed this Notebook. In the next one, we'll see how to calssify clothing images **EASILY**  using the Convolution Neural Networks (CNN). \n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://previews.123rf.com/images/123vector/123vector1409/123vector140900073/31489018-vector-illustration-of-see-you-soon-yellow-note-on-white-background.jpg\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"200\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "     <a href=\"https://github.com/zalandoresearch/fashion-mnist\"></a><br/>\n",
        "  </td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGe9W_cxn2LZ"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.linkedin.com/in/thamer-saraei-472300124/\"><img src=\"http://icons.iconarchive.com/icons/limav/flat-gradient-social/32/Linkedin-icon.png\" />Join me </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.youtube.com/channel/UC8Dt8pO_EqhP9unfnMd-64A?view_as=subscriber\"><img src=\"http://icons.iconarchive.com/icons/emey87/social-button/32/youtube-icon.png\" />Join me </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.facebook.com/timopyr/\"><img src=\"https://icon-icons.com/icons2/1269/PNG/32/1497553311-103_84832.png\" />Join me</a>\n",
        "  </td>\n",
        "</table>"
      ]
    }
  ]
}